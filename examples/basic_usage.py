#!/usr/bin/env python3
"""
Basic usage examples for Multi-AI MCP Integration
"""

import asyncio
import os
import sys

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from multi_ai_integration import MultiAIIntegration, MultiAIConsultationRequest, AIProvider

async def basic_consultation_example():
    """Example: Basic AI consultation with automatic provider selection"""
    print("ü§ñ Basic AI Consultation Example")
    print("=" * 50)
    
    # Initialize the multi-AI system
    multi_ai = MultiAIIntegration()
    
    # Create a consultation request
    request = MultiAIConsultationRequest(
        query="What are the best practices for API authentication?",
        context="Building a RESTful API for a web application",
        preferred_provider=AIProvider.AUTO,
        compare_responses=False
    )
    
    # Perform consultation
    result = await multi_ai.consult_multi_ai(request)
    
    if result["success"]:
        print("‚úÖ Consultation successful!")
        print(f"üìù Summary:\n{result['summary']}")
    else:
        print(f"‚ùå Consultation failed: {result['error']}")

async def provider_specific_example():
    """Example: Consulting specific AI providers"""
    print("\nüéØ Provider-Specific Consultation Example")
    print("=" * 50)
    
    multi_ai = MultiAIIntegration()
    
    # Consult Gemini specifically
    print("üì° Consulting Gemini...")
    gemini_request = MultiAIConsultationRequest(
        query="How should I structure a microservices architecture?",
        context="Designing a scalable e-commerce platform",
        preferred_provider=AIProvider.GEMINI
    )
    
    gemini_result = await multi_ai.consult_multi_ai(gemini_request)
    
    if gemini_result["success"]:
        print("‚úÖ Gemini consultation successful!")
        print(f"üìÑ Response preview: {gemini_result['summary'][:200]}...")
    else:
        print(f"‚ùå Gemini consultation failed: {gemini_result['error']}")
    
    # Consult Llama2 specifically
    print("\nü¶ô Consulting Llama2...")
    llama_request = MultiAIConsultationRequest(
        query="What's a privacy-focused approach to user data handling?",
        context="Implementing GDPR-compliant data processing",
        preferred_provider=AIProvider.LLAMA2
    )
    
    llama_result = await multi_ai.consult_multi_ai(llama_request)
    
    if llama_result["success"]:
        print("‚úÖ Llama2 consultation successful!")
        print(f"üìÑ Response preview: {llama_result['summary'][:200]}...")
    else:
        print(f"‚ùå Llama2 consultation failed: {llama_result['error']}")

async def system_status_example():
    """Example: Checking system status and performance"""
    print("\nüìä System Status Example")
    print("=" * 50)
    
    multi_ai = MultiAIIntegration()
    
    # Check provider availability
    availability = await multi_ai.check_provider_availability()
    print("üîå Provider Availability:")
    for provider, available in availability.items():
        status = "‚úÖ Available" if available else "‚ùå Unavailable"
        print(f"   ‚Ä¢ {provider.title()}: {status}")
    
    # Get comprehensive system status
    status = multi_ai.get_system_status()
    print("\nüìà System Statistics:")
    for provider, info in status["providers"].items():
        if info["available"]:
            stats = info.get("stats", {})
            requests = stats.get("requests", 0)
            successes = stats.get("successes", 0)
            avg_time = stats.get("avg_time", 0.0)
            success_rate = (successes / requests * 100) if requests > 0 else 0
            
            print(f"   ‚Ä¢ {provider.title()}:")
            print(f"     - Requests: {requests}")
            print(f"     - Success Rate: {success_rate:.1f}%")
            print(f"     - Avg Response Time: {avg_time:.2f}s")

async def main():
    """Run all examples"""
    print("üöÄ Multi-AI MCP Integration - Usage Examples")
    print("=" * 60)
    
    try:
        await basic_consultation_example()
        await provider_specific_example()
        await system_status_example()
        
        print("\nüéâ All examples completed successfully!")
        print("\nNext steps:")
        print("‚Ä¢ Try these patterns in Claude Code")
        print("‚Ä¢ Experiment with different query types")
        print("‚Ä¢ Monitor system performance over time")
        
    except KeyboardInterrupt:
        print("\nüõë Examples interrupted")
    except Exception as e:
        print(f"\n‚ùå Example failed: {e}")

if __name__ == "__main__":
    # Set up environment
    if not os.getenv('GOOGLE_API_KEY'):
        print("‚ö†Ô∏è  GOOGLE_API_KEY not set. Some examples may fail.")
        print("   Set it with: export GOOGLE_API_KEY='your-key-here'")
    
    asyncio.run(main())